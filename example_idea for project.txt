Below is a complete, practical, step-by-step workflow you can follow to do ECG signal processing + ML with the MIT-BIH Arrhythmia dataset. I include environment setup, data handling, preprocessing, feature engineering, model training (classical + deep learning), evaluation, explainability, deliverables, pitfalls, and a suggested timeline. This is a ready-to-run roadmap you can follow on your laptop or Colab.

1. Project goal (one-sentence)

Build a reproducible pipeline that loads MIT-BIH ECG data, preprocesses it, extracts beats or windows, trains classifiers (RandomForest baseline → 1D-CNN deep model) to detect/label arrhythmias, and evaluates using patient-level splits and clinically meaningful metrics.

2. Environment & tools

Python 3.10+ (or Colab).

Key libraries:

wfdb (load PhysioNet/MIT-BIH), numpy, pandas, scipy, matplotlib.

pywt (wavelets), sklearn, imbalanced-learn (SMOTE).

tensorflow/keras or pytorch.

seaborn/matplotlib for plots.

shap for explainability (optional).

Install:

pip install wfdb numpy pandas scipy matplotlib scikit-learn imbalanced-learn pywt tensorflow shap


(Use pip install wfdb --upgrade if necessary.)

3. Data acquisition

Register (if required) and download MIT-BIH from PhysioNet or use wfdb to download records programmatically:

import wfdb
wfdb.dl_database('mitdb', dl_dir='mitdb')   # downloads to ./mitdb


Files per record: xxxx.dat, xxxx.hea, xxxx.atr. Keep folder structure.

4. High-level pipeline overview

Load record + annotations.

Inspect & visualize raw ECG + annotation alignment.

Filter / denoise (bandpass + notch + baseline removal).

Detect R-peaks (Pan-Tompkins or refined peak detection).

Segment beats or fixed windows centered on R-peaks.

Map beat annotation symbols → target classes (AAMI grouping or binary).

Extract features (handcrafted) or prepare raw windows for CNN.

Train baseline classical model (RandomForest) on features.

Train end-to-end 1D-CNN on windows.

Evaluate using patient-level holdout and cross-record CV.

Interpret results (confusion matrices, per-class metrics, saliency/SHAP).

Document and present results.

5. Detailed steps & example code snippets
5.1 Loading & inspect
import wfdb
record = wfdb.rdrecord('mitdb/100')        # path to record 100
ann = wfdb.rdann('mitdb/100', 'atr')
signal = record.p_signal[:,0]              # lead 0
fs = record.fs                             # 360
# Quick plot
import matplotlib.pyplot as plt
plt.plot(signal[:3000])
plt.scatter(ann.sample[0:50], signal[ann.sample[0:50]], c='r')  # overlay annotations
plt.show()


Checkpoint: visually confirm R-index annotations align with R-peaks.

5.2 Preprocessing (recommended default)

Bandpass 0.5–40 Hz (preserve QRS + P/T).

Notch at 50/60 Hz (if mains noise present).

Use filtfilt to avoid phase shift.

from scipy.signal import butter, filtfilt, iirnotch

def bandpass(signal, fs, low=0.5, high=40, order=4):
    nyq = 0.5*fs
    b,a = butter(order, [low/nyq, high/nyq], btype='band')
    return filtfilt(b,a,signal)

def notch(signal, fs, freq=50.0, Q=30):
    b,a = iirnotch(freq/(0.5*fs), Q)
    return filtfilt(b,a,signal)

sig_bp = bandpass(signal, fs)
sig_clean = notch(sig_bp, fs, freq=50.0)   # use freq=60 if US


Pitfall: over-filtering distorts morphology. Always plot before/after.

5.3 R-peak detection

Option A: Implement Pan-Tompkins (more robust).

Option B: Use scipy.signal.find_peaks on preprocessed/squared signal for fast dev.

from scipy.signal import find_peaks
squared = sig_clean**2
peaks, _ = find_peaks(squared, distance=int(0.2*fs), height=np.mean(squared)*2.0)


Tip: Tune distance (min RR ~ 0.3s → 0.3*fs) and height. Validate against annotation R indices.

5.4 Segmentation & labeling

Preferred: create windows centered at each R-peak (e.g., 0.3s before → 0.5s after → total 0.8s → 288 samples at 360Hz).

Label each beat by matching to ann.sample (the annotation index nearest the R-peak) and fetch ann.symbol.

window_pre = int(0.3*fs); window_post = int(0.5*fs)
windows = []
labels = []
for r in peaks:
    if r-window_pre < 0 or r+window_post >= len(sig_clean): continue
    win = sig_clean[r-window_pre:r+window_post]
    windows.append(win)
    # find nearest annotation symbol:
    idx = np.argmin(np.abs(ann.sample - r))
    labels.append(ann.symbol[idx])


Label mapping: Convert ann.symbol (many codes) → AAMI classes or binary. (See next section.)

5.5 Label mapping (AAMI EC57 recommended)

Common mapping to AAMI 5 classes:

N (Normal): includes 'N', 'L', 'R', 'e', 'j' (normal beats).

V (Ventricular ectopic): 'V', 'E'.

S (Supraventricular ectopic): 'A', 'a', 'J', 'S'.

F (Fusion beats): 'F'.

Q (Unclassifiable/others): 'Q', '/', etc.

Or use simpler binary: Normal (N) vs Abnormal (everything else) for first pass.

5.6 Feature extraction (classical ML)

Per window (beat) extract:

RR intervals: previous RR, next RR, mean RR.

Time domain: peak amplitude, QRS width estimate, energy, skew, kurtosis.

Frequency: band energies (0.5–5, 5–15, 15–40 Hz).

Wavelet levels: energies from DWT (db4).
Example (RR calc):

rrs = np.diff(ann.sample)/fs    # in seconds
# assign rr to beats (previous RR, next RR etc)


Save features in pandas.DataFrame with label.

5.7 Train/Test split (very important)

Do patient/record-level split, not beat-level. Example: set of records for training, different records for validation/test.

Suggested split: 60% records train, 20% val, 20% test. Use stratification across classes if possible.
Why: beats from same patient are correlated — random beat-level split causes data leakage and inflated performance.

5.8 Baseline model (RandomForest) — fast and informative
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
clf = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=200, class_weight='balanced'))
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_test, y_pred))


Evaluate per-class precision/recall/F1 and confusion matrix.

Use class_weight='balanced' to handle imbalance.

5.9 Deep learning (1D-CNN) — end-to-end on windows

Input: fixed-size 1D windows (e.g., 288 samples).

Data augmentation: add realistic noise, scale, small time shift, mixup.

Architecture sample (Keras):

from tensorflow.keras import layers, models

def build_cnn(input_len, n_classes):
    inp = layers.Input((input_len,1))
    x = layers.Conv1D(32,5,activation='relu')(inp)
    x = layers.MaxPool1D(2)(x)
    x = layers.Conv1D(64,5,activation='relu')(x)
    x = layers.MaxPool1D(2)(x)
    x = layers.Flatten()(x)
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    out = layers.Dense(n_classes, activation='softmax')(x)
    model = models.Model(inp,out)
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model


Train with class_weight or balanced sampling. Use callbacks: EarlyStopping, ModelCheckpoint.

5.10 Handling imbalance

Class weights during training.

SMOTE for feature-level oversampling (not for raw signal windows).

Augmentation for windows (add noise, scale amplitude, time-warp).

Evaluate metrics per-class (macro-F1).

5.11 Evaluation & metrics

Use per-class: Precision, Recall (Sensitivity), F1.

Use Confusion Matrix (rows actual, columns predicted).

For binary detection: compute sensitivity and positive predictive value.

Aggregate results across test records (report mean ± std).

Visualize predicted labels overlaid on ECG traces for manual error analysis.

5.12 Explainability & error analysis

For RandomForest: feature_importances_, SHAP values to see which features drive predictions.

For CNN: 1D saliency maps or GradCAM variant for time-series to see which samples influenced the decision.

Manually review FP/FN beats — often reveals labeling ambiguity, noise, or electrode issues.

6. Deliverables (what to include in final report / demo)

README with setup & how to run.

Notebook(s): preprocessing + feature extraction, model training (RF), CNN training.

Plots: raw vs filtered ECG, QRS detection visualization, confusion matrices, ROC/PR curves (if binary), example saliency maps.

Model weights & sample script to infer on new ECG (e.g., folder of records).

Short slide deck (10–12 slides): problem, data, methods, results, limitations, future work.

7. Common difficulties & suggested solutions (where you will get stuck)

Annotation alignment errors → always visualize.

Bad QRS detection → tune Pan-Tompkins or thresholds; validate vs ann.sample.

Data leakage from beat-level splitting → always split by record.

Class imbalance → use class weights + augmentation + careful metrics.

Overfitting (CNN) → reduce model size / more augmentation / early stopping.

Inconsistent amplitude between records → normalize per-record (z-score) or robust scaling.

8. Practical timeline (6–8 week plan you can follow)

Week 1 — Setup + explore dataset (load, visualize, annotate mapping).
Week 2 — Implement preprocessing & test R-peak detector; validate on multiple records.
Week 3 — Beat/window segmentation + label mapping (AAMI). Start extracting simple features.
Week 4 — Build RandomForest baseline, evaluate patient-level splits, run experiments for imbalance.
Week 5 — Implement data pipeline for windows + simple 1D-CNN; run small experiments on Colab.
Week 6 — Hyperparameter tuning, augmentation, evaluation, explainability (SHAP/saliency).
Week 7 — Finalize results, build demo notebook, prepare slides and report. (Optional Week 8: extra experiments or deploy demo.)

9. Quick checklist to follow during development

 Visualize raw and filtered signals for each record.

 Confirm annotation alignment for several records.

 Use patient-level splits only.

 Track per-class metrics, not only accuracy.

 Save random seeds and model checkpoints for reproducibility.

 Log experiments (weights, metrics) — use a CSV or a simple tool like mlflow or wandb.

10. Example next step for me to produce (I can generate now)

I can produce any one of the following immediately (copy-paste runnable):

A Jupyter notebook that downloads MIT-BIH via wfdb, shows a visualization, does bandpass + notch filtering, and implements Pan-Tompkins or peak finding with plots.

A Feature extraction + RandomForest notebook (preprocess a few records → extract features → train/evaluate RF with patient-level split).

A 1D-CNN notebook that builds the window dataset and trains a CNN on a small set of records (Colab friendly).